üìò Dokumentationsleitfaden f√ºr Flowcharts & KNIME-Workflows (Data Analytics)
üéØ Zweck des Leitfadens

Dieser Leitfaden soll sicherstellen, dass:

Workflows verst√§ndlich, wartbar und reproduzierbar sind

Teammitglieder Prozesse nachvollziehen k√∂nnen

√úbergaben und Reviews effizient funktionieren

zuk√ºnftige Anpassungen ohne Risiko m√∂glich sind

1Ô∏è‚É£ Allgemeine Projekt-Dokumentation
1. Projektsteckbrief

Kurze √úbersicht, gern auf 1 Seite:

Projektname

Zielsetzung / Business Problem

Owner / Verantwortliche

Datenquellen

Hauptoutputs (Dashboards, Modelle, Reports)

Stakeholder

Version / Datum

2. Datenbeschreibung

F√ºr alle verwendeten Datens√§tze:

Name und Speicherort

Format (CSV, SQL etc.)

Quelle (intern, extern, API etc.)

Update-Zyklus / Refresh

Schema (Spalten, Datentypen)

Relevante Qualit√§tsprobleme

Zugriffsrechte / Sensitivit√§t

2Ô∏è‚É£ Dokumentation von Flowcharts / Prozessdiagrammen
1. Ziel des Flowcharts

Beschreibe kurz:

Was zeigt das Diagramm?

Was soll damit erreicht werden?

Wo im √ºbergeordneten Prozess befindet es sich?

2. Konventionen

Leg Standard-Icons / Farben fest:

Blau: Dateninput

Gelb: Transformation / Verarbeitung

Gr√ºn: Output / Ergebnisse

Rot: Fehlerbehandlung

Orange: Entscheidungen

‚Üí Optional kannst du eine kleine Legende am Rand einbauen.

3. Detail-Kommentare

Jedes Element sollte enthalten:

klare Bezeichnung

kurze Beschreibung (1‚Äì2 S√§tze)

Verweise auf KNIME-Knoten (falls relevant)

4. Versionierung

Im Flowchart dokumentieren:

Versionsnummer

Datum

Ersteller / Reviewer

3Ô∏è‚É£ KNIME-Workflow Dokumentation
üîß A. Struktur & Naming Conventions
1. Ordner- und Workflowstruktur

Empfohlen:

/01_raw
/02_preprocessing
/03_feature_engineering
/04_modeling
/05_evaluation
/06_output
/99_archive

2. Benennung von Knoten

Kurze, klare, sprechende Namen:

Beispiel	Schlecht	Gut
Node Name	"Node 45"	"Remove Outliers"
Metanode	"Metanode1"	"Customer Cleaning Pipeline"

Regel:
‚û°Ô∏è Verb + Objekt (‚ÄûCalculate Mean‚Äú, ‚ÄûJoin Customer Data‚Äú)

üóÇÔ∏è B. Metanodes & Components

Jede Metanode/Component enth√§lt:

Beschreibung der Funktion

Input/Output-Spezifikation

Parameterbeschreibung

Risiken oder bekannte Probleme

Beispieloutput (falls sinnvoll)

üìù C. Dokumentation innerhalb des Workflows
1. Annotationen

Nutze die eingebaute Kommentarfunktion mit:

grauen Boxen f√ºr Kontext

gelbe Boxen f√ºr wichtige Hinweise

rote Boxen f√ºr Risiken / Fehlerquellen

2. Start-Annotation

Am Anfang des Workflows:

Workflow-Zweck

Erwartete Inputs

Hauptoutputs

Version & Datum

3. Abschnittskommentare

Vor jedem Block:

Kurze √úbersicht (z. B. ‚ÄûDatenbereinigung‚Äú)

Auflistung der wichtigsten Schritte

üìä D. Parameter- & Modell-Dokumentation
1. Parameterliste

Tabellarisch:

Parameter	Wert	Beschreibung	Warum?
Min Frequency	5	Filter	Entfernt seltene Kategorien
2. Machine Learning Modelle

F√ºr jedes Modell:

Modelltyp

Train/Test-Split

Featureliste

Hyperparameter

Performance-Metriken

Interpretationshinweise

Version des Trainingsdatensatzes

4Ô∏è‚É£ Reproduzierbarkeit & Governance
1. Code / Workflow Versionierung

Git oder KNIME Server verwenden

Commit Messages nach Standard:
feat: added outlier filter
fix: corrected wrong join condition

2. Datenversionierung

Input-Datasets mit Zeitstempel ablegen

Wichtige Datensnapshots im Projekt speichern

3. Logging

Mindestens:

Workflow-Run

verwendete Datenversion

Erstellte Outputs

Warnungen / Fehler

5Ô∏è‚É£ √úbergabe-Dokumentation (f√ºr Team oder Kunden)
Kurz-Report (1‚Äì3 Seiten)

Was macht der Workflow?

Welche Daten?

Wie wird er ausgef√ºhrt?

Welche Outputs entstehen?

Wo liegen Stolperfallen?

Technische √úbergabe

KNIME-Workflow (.knwf)

README

Beispiel-Dataset

Beispiel-Output

6Ô∏è‚É£ Vorlagen / Templates
README-Template
# Projektname

## 1. Ziel
<Kurze Beschreibung>

## 2. Datenquellen
- <Datenquelle 1>
- <Datenquelle 2>

## 3. Workflowbeschreibung
<1‚Äì2 Abs√§tze>

## 4. Ordnerstruktur
<Struktur>

## 5. Ausf√ºhrung
- Schritt 1 ‚Ä¶
- Schritt 2 ‚Ä¶

## 6. Outputs
- <Output 1>
- <Output 2>

## 7. Version
v1.0 ‚Äì <Datum>
Autor: <Name>





[Start]
   |
   v
[Load Raw Data]
   |
   v
[Check Schema]
   |
   v
[Data Cleaning?] ----No----> [Proceed]
       | 
      Yes
       |
       v
[Handle Missing Values]
   |
   v
[Remove Duplicates]
   |
   v
[Outlier Detection]
   |
   v
[Data Transformation Needed?] ---No---> [Proceed]
                |
               Yes
                |
                v
[Feature Engineering]
   |
   v
[Train/Test Split]
   |
   v
[Model Training]
   |
   v
[Model Evaluation]
   |
   v
[Export Results / Dashboard]
   |
   v
[End]



1. Beispiel-Flowchart (Data Cleaning & Analysis in KNIME)

Du kannst dieses Flowchart 1:1 in Draw.io, Miro, PowerPoint oder Visio nachbauen.

[Start]
   |
   v
[Load Raw Data]
   |
   v
[Check Schema]
   |
   v
[Data Cleaning?] ----No----> [Proceed]
       | 
      Yes
       |
       v
[Handle Missing Values]
   |
   v
[Remove Duplicates]
   |
   v
[Outlier Detection]
   |
   v
[Data Transformation Needed?] ---No---> [Proceed]
                |
               Yes
                |
                v
[Feature Engineering]
   |
   v
[Train/Test Split]
   |
   v
[Model Training]
   |
   v
[Model Evaluation]
   |
   v
[Export Results / Dashboard]
   |
   v
[End]


Legende (konform zu Leitfaden):
üü¶ Input / Datenquellen
üü® Transformation / Prozess
üü© Output
üü• Entscheidung
üüß Modellierung

‚≠ê 2. Word-/PDF-Vorlage ‚Äì Dokumentationsleitfaden (kompletter Text zum Kopieren)

Du kannst diesen Inhalt direkt in Word, Google Docs oder PDF √ºbernehmen.

DOKUMENTATIONSLEITFADEN ‚Äì Data Analytics & KNIME Workflow
1. Projektdetails

Projektname:

Version:

Datum:

Autor:

Kurzbeschreibung (max. 5 S√§tze):

2. Daten√ºbersicht
Datensatz	Quelle	Format	Update-Zyklus	Sensitivit√§t	Beschreibung
3. Workflow-Zweck

Beschreibe:

Was tut der Workflow?

Welche Hauptoutputs werden erzeugt?

F√ºr wen ist der Workflow gedacht?

4. Workflow-√úberblick

Kurzer Abschnitt (1‚Äì2 Abs√§tze):

Welche Schritte enth√§lt der Prozess?

Welche Logik steckt dahinter?

Wie ist der Workflow strukturiert?

Optional: Flowchart einf√ºgen.

5. Struktur (Ordner & KNIME-Teile)
5.1 Ordnerstruktur
/01_raw
/02_preprocessing
/03_feature_engineering
/04_modeling
/05_evaluation
/06_output
/99_archive

5.2 KNIME Workflow-Struktur
Abschnitt	Beschreibung	Wichtige Knoten	Outputs
6. Knoten- und Component-Dokumentation

F√ºr jeden Teil:

Beispiel:

Metanode: Customer Cleaning
Zweck: Entfernt Fehler, Duplikate, formatiert Daten
Inputs: customers_raw
Outputs: customers_clean
Parameter:

Missing Value Threshold: 30%

Outlier Method: IQR (1.5)

7. Modell-Dokumentation (falls relevant)
Modelltyp	Parameter	Featureliste	Trainingsdatenversion	Performance	Kommentar
8. Ausf√ºhrung

Schritt 1: Daten bereitstellen

Schritt 2: Workflow starten

Schritt 3: Outputs pr√ºfen

Schritt 4: Ergebnisse exportieren

9. Risiken & Stolperfallen

Daten k√∂nnen fehlen wenn ‚Ä¶

Join-Key empfindlich gegen√ºber ‚Ä¶

Modell abh√§ngig von ‚Ä¶

Workflow scheitert wenn ‚Ä¶

10. Versionierungshinweise

Commit-Format:

feat: added cleaning pipeline  
fix: corrected join key  
refactor: reorganized modeling section  

11. Anh√§nge

Beispiel-Output

Screenshots

Flowchart

‚≠ê 3. Checkliste f√ºr Workflow-Reviews

Perfekt f√ºr dich oder Teamkollegen ‚Äì H√§kchenliste:

‚úî Struktur

 Workflow folgt einer klaren Sektionierung

 Benennung der Knoten ist einheitlich

 Keine unbenannten Knoten

 Alle Metanodes haben Beschreibung

‚úî Daten

 Alle Datenquellen dokumentiert

 Eingangsdatensatz validiert

 Missing Values behandelt

 Duplikate gepr√ºft

‚úî Logik

 Jeder Prozessschritt ist nachvollziehbar

 Join Keys klar dokumentiert

 Ausrei√üer-Handling korrekt

 Transformationen erkl√§rt

‚úî Parameter

 Alle wichtigen Parameter dokumentiert

 Defaults bewusst gew√§hlt

 Modellparameter nachvollziehbar

‚úî Annotationen in KNIME

 Jeder Abschnitt hat Annotation

 Startbereich erkl√§rt Zweck

 Risiken markiert

 Outputs klar benannt

‚úî Ausgabedaten

 Outputs sauber formatiert

 Dateinamen konsistent

 Ergebnisse plausibilisiert

‚úî Reproduzierbarkeit

 Versionen dokumentiert

 Eingangsdatensatz gespeichert

 Zufallsseed gesetzt (falls CI/ML)

 Ausf√ºhrungsschritte beschrieben

‚≠ê 4. Beispiel-KNIME-Workflow mit Kommentaren (zum Nachbauen)

Nach KNIME-Logik aufgebaut:

[Input Section]
  - File Reader (customers_raw.csv)
  - Annotation: "Rohdaten ‚Äì keine √Ñnderungen!"

[Validation Section]
  - Table Schema Inspector
  - Missing Value Counter
  - Annotation: "Validierung, bevor wir mit Cleaning starten"

[Cleaning Section]
  - Missing Value Node (Mean for numeric, Most frequent for categorical)
  - Duplicate Row Filter
  - String Manipulation (trim, lowercase)
  - Numeric Outliers (IQR)
  - Annotation: "Datenbereinigung Teil 1"

[Feature Engineering Section]
  - Math Formula (new features)
  - One-Hot Encoding
  - Normalization
  - Annotation: "Neue Variablen f√ºr Modell"

[Split Section]
  - Partitioning (70/30)
  - Annotation: "Train/Test Split, Seed = 42"

[Model Section]
  - Random Forest Learner
  - Random Forest Predictor
  - Annotation: "Modelltraining + Anwendung"

[Evaluation Section]
  - Scorer (Accuracy, Precision, Recall)
  - ROC Curve
  - Annotation: "Modellbewertung"

[Output Section]
  - Excel Writer (results.xlsx)
  - Annotation: "Finale Ergebnisse"